{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q langchain-openai langchain playwright beautifulsoup4\n",
    "# %playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "USER_AGENT = os.getenv(\"USER_AGENT\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from langchain_community.document_loaders import AsyncChromiumLoader\n",
    "from playwright.async_api import TimeoutError as PlaywrightTimeoutError\n",
    "\n",
    "class RobustChromiumLoader(AsyncChromiumLoader):\n",
    "    \"\"\"\n",
    "    Ultimate Fix: Handles:\n",
    "    - Late JavaScript navigation\n",
    "    - Unwanted dynamic changes\n",
    "    - Auto-redirects\n",
    "    - Pop-ups & unnecessary elements\n",
    "    \"\"\"\n",
    "    async def _fetch(self, page, url):\n",
    "        try:\n",
    "            # Set User-Agent to mimic a real browser\n",
    "            await page.set_extra_http_headers({\"User-Agent\": USER_AGENT})\n",
    "\n",
    "            # Block auto-navigation & unnecessary assets (ads, images, tracking scripts)\n",
    "            async def block_unwanted(route):\n",
    "                if route.request.resource_type in [\"image\", \"font\", \"stylesheet\", \"media\"]:\n",
    "                    await route.abort()\n",
    "                else:\n",
    "                    await route.continue_()\n",
    "            await page.route(\"**/*\", block_unwanted)\n",
    "\n",
    "            # **Prevent Unwanted Redirections**\n",
    "            async def intercept_navigation(request):\n",
    "                if request.is_navigation_request():\n",
    "                    await request.abort()  # Block redirects\n",
    "            await page.route(\"**/*\", intercept_navigation)\n",
    "\n",
    "            # Go to the page, ensuring full JavaScript execution\n",
    "            await page.goto(url, wait_until=\"domcontentloaded\", timeout=25000)\n",
    "            await page.wait_for_load_state(\"networkidle\")\n",
    "\n",
    "            # Ensure key elements are present before extracting\n",
    "            await page.wait_for_selector(\"body\", timeout=10000)\n",
    "\n",
    "            # **Handle Delayed Content**: Wait for final JavaScript updates\n",
    "            await asyncio.sleep(2)  # Ensures async-loaded content is fully rendered\n",
    "\n",
    "            # **Safe Extraction**: Avoids page.content() error\n",
    "            html_handle = await page.evaluate_handle(\"document.documentElement.outerHTML\")\n",
    "            html_content = await html_handle.json_value()  # Convert to string\n",
    "            \n",
    "            return html_content\n",
    "\n",
    "        except PlaywrightTimeoutError:\n",
    "            print(f\"‚è≥ Timeout while loading {url}. Retrying...\")\n",
    "            return await self._retry_fetch(page, url)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    async def _retry_fetch(self, page, url, retries=3):\n",
    "        \"\"\"Retry fetching the page with incremental wait times.\"\"\"\n",
    "        wait_times = [3, 5, 8]  # Gradual increase in delay before retrying\n",
    "        for attempt, wait_time in enumerate(wait_times, start=1):\n",
    "            try:\n",
    "                print(f\"üîÑ Retrying ({attempt}/{retries}) for {url}, waiting {wait_time}s...\")\n",
    "                await asyncio.sleep(wait_time)\n",
    "                await page.goto(url, wait_until=\"domcontentloaded\", timeout=25000)\n",
    "                await page.wait_for_load_state(\"networkidle\")\n",
    "                await page.wait_for_selector(\"body\", timeout=10000)\n",
    "                html_handle = await page.evaluate_handle(\"document.documentElement.outerHTML\")\n",
    "                return await html_handle.json_value()\n",
    "            except PlaywrightTimeoutError:\n",
    "                continue\n",
    "        print(f\"‚ùå Final retry failed for {url}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import Html2TextTransformer\n",
    "\n",
    "async def fetch_and_extract_text(urls):\n",
    "    loader = RobustChromiumLoader(urls=urls)\n",
    "    docs = await loader.aload()\n",
    "\n",
    "    if not docs:\n",
    "        return None\n",
    "\n",
    "    transformer = Html2TextTransformer()\n",
    "    extracted_docs = transformer.transform_documents(docs)\n",
    "    \n",
    "    return extracted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_documents_to_files(documents, directory=\"./output/\"):\n",
    "    \"\"\"\n",
    "    Saves each extracted document to a .txt file.\n",
    "    \"\"\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    for index, doc in enumerate(documents):\n",
    "        content = doc.page_content\n",
    "        file_path = os.path.join(directory, f\"file_{index + 1}.txt\") \n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.vensure.com/\",\n",
    "]\n",
    "\n",
    "DIR_Html2TextTransformer = \"./html2text_output/\"\n",
    "\n",
    "documents = await fetch_and_extract_text(urls)\n",
    "\n",
    "if documents:\n",
    "    save_documents_to_files(documents, DIR_Html2TextTransformer)\n",
    "else:\n",
    "    print(\"No content extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
